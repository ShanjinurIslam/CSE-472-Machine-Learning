{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv',header=None)\n",
    "valid_rating_count = df[df.columns[0]]\n",
    "df = df.drop(columns=df.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_rating_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "def train_test_split(X,no_rating=99,valid_rating_count=None,train_ratio=0.6,validation_ratio=0.2,test_ratio=0.2):\n",
    "    N = X.shape[0]\n",
    "    M = X.shape[1]\n",
    "    \n",
    "    training_set = np.ones((N,M))*99\n",
    "    validation_set = np.ones((N,M))*99\n",
    "    test_set = np.ones((N,M))*99\n",
    "    \n",
    "    for i in range(N):\n",
    "        valid_indices = []\n",
    "        for j in range(M):\n",
    "            if X[i][j]!=99:\n",
    "                valid_indices.append(j)\n",
    "        \n",
    "        if valid_rating_count is not None and valid_rating_count[i]!=len(valid_indices):\n",
    "            print(\"Error at row index \",i)\n",
    "            continue\n",
    "            \n",
    "        np.random.shuffle(valid_indices) # uniform distribution of indicies\n",
    "        \n",
    "        total_valid_indices_size = len(valid_indices)\n",
    "        training_set_size = int(round(train_ratio*total_valid_indices_size))\n",
    "        validation_set_size = int(round(validation_ratio*total_valid_indices_size))\n",
    "        test_set_size = int(round(validation_ratio*total_valid_indices_size))\n",
    "        \n",
    "        training_indices = valid_indices[0:training_set_size]\n",
    "        validation_indices = valid_indices[training_set_size:training_set_size+validation_set_size]\n",
    "        test_indicies = valid_indices[training_set_size+validation_set_size:total_valid_indices_size]\n",
    "        \n",
    "        for j in training_indices:\n",
    "            training_set[i][j] = X[i][j]\n",
    "        \n",
    "        for j in validation_indices:\n",
    "            validation_set[i][j] = X[i][j]\n",
    "        \n",
    "        for j in test_indicies:\n",
    "            test_set[i][j] = X[i][j]\n",
    "            \n",
    "    return training_set,validation_set,test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,val_set,test_set = train_test_split(X,no_rating=99,valid_rating_count=valid_rating_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(data, U, V, l_u, l_v):\n",
    "    N = data.shape[0]\n",
    "    M = data.shape[1]\n",
    "    pred = U*V.T\n",
    "    error_val = 0.0\n",
    "    count = 0.0\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            if not data[i, j] == 99:\n",
    "                count += 1.0\n",
    "                error_val += math.pow(data[i,j]-pred[i,j],2)\n",
    "    error_val += l_u*np.sum(np.square(U))\n",
    "    error_val += l_v*np.sum(np.square(V))\n",
    "    return error_val\n",
    "\n",
    "\n",
    "def r_error(data, U, V):\n",
    "    N = data.shape[0]\n",
    "    M = data.shape[1]\n",
    "    pred = U*V.T\n",
    "    error_val = 0.0\n",
    "    count = 0.0\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            if not data[i, j] == 99:\n",
    "                count += 1.0\n",
    "                error_val += math.pow(data[i,j]-pred[i,j],2)\n",
    "    return math.sqrt(error_val/count)\n",
    "\n",
    "\n",
    "def als(data, K, lambda_u, lambda_v, tolerance):\n",
    "    N = data.shape[0]\n",
    "    M = data.shape[1]\n",
    "    I = np.mat(np.identity(K))\n",
    "    U = np.mat(np.random.uniform(-10,10,(N,K)))\n",
    "    V = np.mat(np.zeros((M,K)))\n",
    "    prev_error = None\n",
    "\n",
    "    while True:\n",
    "        for i in range(M):\n",
    "            temp1 = np.mat(np.zeros((K,K)))\n",
    "            temp2 = np.mat(np.zeros((K,1)))\n",
    "            for j in range(N):\n",
    "                if not data[j, i] == 99:\n",
    "                    temp1 = temp1 + U[j].T*U[j] + lambda_v*I\n",
    "                    temp2 = temp2 + data[j, i]*U[j].T\n",
    "            V[i] = (np.linalg.inv(temp1)*temp2).T\n",
    "\n",
    "        for i in range(N):\n",
    "            temp1 = np.mat(np.zeros((K, K)))\n",
    "            temp2 = np.mat(np.zeros((K, 1)))\n",
    "            for j in range(M):\n",
    "                if not data[i, j] == 99:\n",
    "                    temp1 = temp1 + V[j].T * V[j] + lambda_u * I\n",
    "                    temp2 = temp2 + data[i, j] * V[j].T\n",
    "            U[i] = (np.linalg.inv(temp1) * temp2).T\n",
    "\n",
    "        if prev_error is None:\n",
    "            prev_error = error(data,U,V,lambda_u,lambda_v)\n",
    "        else:\n",
    "            curr_error = error(data,U,V,lambda_u,lambda_v)\n",
    "            difference = abs(prev_error-curr_error)\n",
    "            change = difference/curr_error\n",
    "            if change < tolerance:\n",
    "                print(curr_error)\n",
    "                break\n",
    "            prev_error = curr_error\n",
    "        print(prev_error)\n",
    "    return U, V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_factors = [5,10,20,40]\n",
    "lambda_values = [10.0,1.0,0.1,0.01]\n",
    "lowest_error = None\n",
    "best_k = None\n",
    "best_l_u = None\n",
    "best_l_v = None\n",
    "best_U = None\n",
    "best_V = None\n",
    "\n",
    "for k in latent_factors:\n",
    "    for l_u in lambda_values:\n",
    "        for l_v in lambda_values:\n",
    "            U,V = als(train_set,k,l_u,l_v,0.00005)\n",
    "            curr_error = r_error(train_set,U,V)\n",
    "            print(k,l_u,l_v,curr_error)\n",
    "            if lowest_error is None or lowest_error>curr_error:\n",
    "                lowest_error = curr_error\n",
    "                best_k = k\n",
    "                best_l_u = l_u\n",
    "                best_l_v = l_v\n",
    "                best_U = U\n",
    "                best_V = V\n",
    "\n",
    "output = open('model.pk1','wb')\n",
    "pickle.dump(U,output,pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(V,output,pickle.HIGHEST_PROTOCOL)\n",
    "output.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
