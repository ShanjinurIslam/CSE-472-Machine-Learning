{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required python module(s)\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n 2. 3. 3. 3. 3. 3.]\n"
    }
   ],
   "source": [
    "#load data from file\n",
    "data = np.genfromtxt('iris_multiclass.csv', delimiter=',',skip_header=True)\n",
    "\n",
    "#Distribute data into train and test sets\n",
    "X_train = data[:120,[0,1,2,3]]\n",
    "Y_train = data[:120,5]\n",
    "\n",
    "X_test = data[-30:,[0,1,2,3]]\n",
    "Y_test = data[-30:,5]\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the required Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-1.3879260321845126\n[[ 0.28590272]\n [ 0.46011454]\n [ 1.60972781]\n [-2.50791129]\n [-1.14796962]]\n-64.76128269268942\n[[ 0.63087103]\n [ 0.42606365]\n [-1.40136046]\n [ 0.32136084]\n [-0.77762565]]\n-19.378481198390663\n[[-0.93309689]\n [-1.69285985]\n [-1.54003974]\n [ 2.58282908]\n [ 2.00266044]]\n"
    }
   ],
   "source": [
    "#Define the Raw implementation function to set the parameters (theta)\n",
    "\n",
    "def fit_implementation(X_train, Y_train, learning_rate=0.0005, max_iteration=1000, debug=False):\n",
    "    #Adding a column of 1's so that the first element of each input is always 1\n",
    "    #It would be multiplied with theta_0 later\n",
    "    X_train= np.insert(X_train, 0, values=1, axis=1)\n",
    "    no_attributes = X_train.shape[1]\n",
    "    \n",
    "    #Initialize model parameters theta\n",
    "    theta = np.zeros((no_attributes,1))\n",
    "    \n",
    "    #Run number of iterations\n",
    "    for icount in range(max_iteration):\n",
    "        #delta is the quantity that will be added with theta during updating theta\n",
    "        delta = np.zeros((no_attributes,1))\n",
    "        totalLogLikelihood = 0\n",
    "        #Check each data point\n",
    "        for instance, actualOutput in zip(X_train,Y_train):\n",
    "            instance=instance.reshape(no_attributes,1)\n",
    "            dotResult = np.dot(theta.T, instance)\n",
    "            \n",
    "            predictedValue=sigmoid(dotResult).squeeze()\n",
    "            #Calculate the derivative value for this data point\n",
    "            derivativeValue = instance*(actualOutput-predictedValue)\n",
    "            #Calculate the amount to be added with theta\n",
    "            delta += learning_rate*derivativeValue\n",
    "\n",
    "            logLikelihood = actualOutput*np.log(predictedValue)+(1-actualOutput)*np.log(1-predictedValue)\n",
    "            totalLogLikelihood += logLikelihood\n",
    "        theta = theta + delta\n",
    "        \n",
    "        #After each 100 iteration, print the status\n",
    "        if icount%100==0 and debug==True:\n",
    "            print(icount)\n",
    "            print(totalLogLikelihood)\n",
    "            print(theta)\n",
    "            \n",
    "    print(totalLogLikelihood)\n",
    "    print(theta)\n",
    "    \n",
    "    return theta\n",
    "\n",
    "\n",
    "def multciClassFitImplementation(X_train, Y_train):\n",
    "    #Determine the list unique classes (unique target variable values) \n",
    "    #Changes required here\n",
    "    unique_classes = np.unique(Y_train)\n",
    "\n",
    "    #For each uniqueclass, determine the best classifier/parameter/theta which best separates the class with others\n",
    "    #You can temporarily modify Y_train data to achieve the target and can call the fit_implementation function\n",
    "    parameters = dict()\n",
    "\n",
    "    #class_wise_target = []\n",
    "    #Changes required here\n",
    "    for each_class in unique_classes:\n",
    "        temp_Y = (Y_train==each_class).astype(int)\n",
    "        parameters[each_class] = fit_implementation(X_train,temp_Y,max_iteration=1000,debug=False)\n",
    "    \n",
    "    return parameters\n",
    "        \n",
    "parameters = multciClassFitImplementation(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9697683923707109 1.0 1.0\n0.9890910258920178 1.0 1.0\n0.9783928902171469 1.0 1.0\n0.9908882941076916 1.0 1.0\n0.984600599550169 1.0 1.0\n0.38952320581739663 2.0 2.0\n0.3000647046445209 2.0 2.0\n0.40968262184108 2.0 2.0\n0.5064051681035897 2.0 2.0\n0.4472710056158424 2.0 2.0\n0.7579463324970365 3.0 3.0\n0.7809116479331422 3.0 3.0\n0.7066620010675335 3.0 3.0\n0.8685767540093352 3.0 3.0\n0.7748892942898554 3.0 3.0\n0.9902031306978576 1.0 1.0\n0.9208619677655475 1.0 1.0\n0.9815062786088594 1.0 1.0\n0.9712258873104448 1.0 1.0\n0.9713972683520286 1.0 1.0\n0.3943257386613801 2.0 2.0\n0.2605286759263265 2.0 2.0\n0.41051977878748 2.0 2.0\n0.46164855771225216 2.0 2.0\n0.31590832996990326 2.0 2.0\n0.9021060040231639 3.0 3.0\n0.5964257475129733 3.0 3.0\n0.887723108886421 3.0 3.0\n0.9221654716528381 3.0 3.0\n0.9146192987919184 3.0 3.0\nTotal Correct Count:  30  Total Wrong Count:  0  Accuracy:  100.0\n"
    }
   ],
   "source": [
    "#One of the following parameters of the function is now thetas which is a dictionary containing (targetClass,theta) \n",
    "#as (key,value) pairs for all target classes\n",
    "def prediction(X_test, Y_test, thetas):\n",
    "    #Adding a column of 1's so that the first element of each input is always 1\n",
    "    #It would be multiplied with theta_0 later\n",
    "    X_test= np.insert(X_test, 0, values=1, axis=1)\n",
    "    no_attributes = X_test.shape[1]\n",
    "    \n",
    "    correctCount = 0\n",
    "    totalCount = 0\n",
    "    \n",
    "    maxPredictedValue = -10000\n",
    "    predictedClass = 1.0\n",
    "    \n",
    "    #Check each data point\n",
    "    for instance, actualOutput in zip(X_test,Y_test):\n",
    "            instance=instance.reshape(no_attributes,1)\n",
    "            #Determine the maximum predicted value and predictedClass\n",
    "            for key in parameters.keys():\n",
    "                h_theta = sigmoid(np.dot(thetas[key].T,instance)[0][0])\n",
    "                if(h_theta>maxPredictedValue):\n",
    "                    maxPredictedValue = h_theta\n",
    "                    predictedClass = key\n",
    "\n",
    "            print(maxPredictedValue, predictedClass, actualOutput)\n",
    "            if predictedClass == actualOutput:\n",
    "                correctCount += 1\n",
    "            totalCount += 1\n",
    "\n",
    "            maxPredictedValue = -10000\n",
    "            predictedClass = 1.0\n",
    "    print(\"Total Correct Count: \",correctCount,\" Total Wrong Count: \",totalCount-correctCount,\" Accuracy: \",(correctCount*100)/(totalCount))\n",
    "    \n",
    "prediction(X_test, Y_test, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Output: \n",
    "Total Correct Count:  30  Total Wrong Count:  0  Accuracy:  100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}